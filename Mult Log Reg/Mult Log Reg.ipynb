{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import genfromtxt\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, LeaveOneOut, KFold\n",
    "from sklearn.metrics import classification_report, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cultivar</th>\n",
       "      <th>alco</th>\n",
       "      <th>malic</th>\n",
       "      <th>ash</th>\n",
       "      <th>alk</th>\n",
       "      <th>magn</th>\n",
       "      <th>tot_phen</th>\n",
       "      <th>flav</th>\n",
       "      <th>nonfl_phen</th>\n",
       "      <th>proanth</th>\n",
       "      <th>color_int</th>\n",
       "      <th>hue</th>\n",
       "      <th>OD280rat</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cultivar   alco  malic   ash   alk  magn  tot_phen  flav  nonfl_phen  \\\n",
       "0         1  14.23   1.71  2.43  15.6   127      2.80  3.06        0.28   \n",
       "1         1  13.20   1.78  2.14  11.2   100      2.65  2.76        0.26   \n",
       "2         1  13.16   2.36  2.67  18.6   101      2.80  3.24        0.30   \n",
       "3         1  14.37   1.95  2.50  16.8   113      3.85  3.49        0.24   \n",
       "4         1  13.24   2.59  2.87  21.0   118      2.80  2.69        0.39   \n",
       "\n",
       "   proanth  color_int   hue  OD280rat  proline  \n",
       "0     2.29       5.64  1.04      3.92     1065  \n",
       "1     1.28       4.38  1.05      3.40     1050  \n",
       "2     2.81       5.68  1.03      3.17     1185  \n",
       "3     2.18       7.80  0.86      3.45     1480  \n",
       "4     1.82       4.32  1.04      2.93      735  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine=pd.read_csv('data/strongdrink.txt')\n",
    "print (wine.shape)\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "X = wine[['alco','malic','tot_phen','color_int']]\n",
    "y = wine['cultivar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of each Cultivar in original data: (array([1, 2, 3]), array([59, 71, 46]))\n",
      "Number of each Cultivar in test data: (array([1, 2, 3]), array([46, 50, 36]))\n",
      "Number of each Cultivar in test data: (array([1, 2, 3]), array([13, 21, 10]))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size = 0.25,\n",
    "       random_state=20)\n",
    "\n",
    "#Count number of each cultivar in test set\n",
    "\n",
    "print('Number of each Cultivar in original data:' ,np.unique(y, return_counts=True))\n",
    "print('Number of each Cultivar in test data:' ,np.unique(y_train, return_counts=True))\n",
    "print('Number of each Cultivar in test data:' ,np.unique(y_test, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The coefficients for Cultivar 1 are: [-1.46798523 -0.33305092  0.66400603 -0.92270882]\n",
      "The coefficients for Cultivar 2 are: [-0.2324475   0.59866064 -1.8879004   0.89996106]\n"
     ]
    }
   ],
   "source": [
    "LogReg = LogisticRegression(random_state=0, multi_class='multinomial',solver='newton-cg')\n",
    "LogReg.fit(X_train, y_train)\n",
    "y_pred = LogReg.predict(X_test)\n",
    "\n",
    "print('The coefficients for Cultivar 1 are:', LogReg.coef_[1])\n",
    "print('The coefficients for Cultivar 2 are:', LogReg.coef_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 2 19  0]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       1.00      0.90      0.95        21\n",
      "           3       1.00      1.00      1.00        10\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        44\n",
      "   macro avg       0.96      0.97      0.96        44\n",
      "weighted avg       0.96      0.95      0.96        44\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cultivar 1 error rate = 0.13\n",
      "Cultivar 2 error rate = 0.0\n",
      "Cultivar 3 error rate = 0.0\n"
     ]
    }
   ],
   "source": [
    "print('Cultivar 1 error rate = 0.13')\n",
    "print('Cultivar 2 error rate = 0.0')\n",
    "print('Cultivar 3 error rate = 0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.045454545454545456\n"
     ]
    }
   ],
   "source": [
    "#Because the \n",
    "mse_test = np.sum(y_test != y_pred)/(y_pred.shape[0])\n",
    "\n",
    "print('MSE:', mse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE loocv= 0.07954545454545454\n"
     ]
    }
   ],
   "source": [
    "Xvals = X.values\n",
    "yvals = y.values\n",
    "N_loo = Xvals.shape[0]\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(Xvals)\n",
    "\n",
    "y_test_vec = np.zeros(N_loo)\n",
    "y_pred_vec = np.zeros(N_loo)\n",
    "\n",
    "for train_index, test_index in loo.split(Xvals):\n",
    "    X_trainb, X_testb = Xvals[train_index], Xvals[test_index]\n",
    "    y_trainb, y_testb = yvals[train_index], yvals[test_index]\n",
    "    LogReg = LogisticRegression(random_state=0, multi_class='multinomial',solver='newton-cg')\n",
    "    LogReg.fit(X_trainb, y_trainb)\n",
    "    y_predb = LogReg.predict(X_testb)\n",
    "    y_test_vec[test_index]=y_testb\n",
    "    y_pred_vec[test_index]=y_predb\n",
    "\n",
    "\n",
    "mse_test_loo = np.sum(y_test_vec != y_pred_vec)/(y_pred_vec.shape[0])\n",
    "\n",
    "print('test estimate MSE loocv=', mse_test_loo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55,  4,  0],\n",
       "       [ 5, 64,  2],\n",
       "       [ 1,  2, 43]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrixloo = confusion_matrix(y_test_vec, y_pred_vec)\n",
    "confusion_matrixloo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.90      0.93      0.92        59\n",
      "         2.0       0.91      0.90      0.91        71\n",
      "         3.0       0.96      0.93      0.95        46\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       176\n",
      "   macro avg       0.92      0.92      0.92       176\n",
      "weighted avg       0.92      0.92      0.92       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_vec, y_pred_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test estimate MSE k-fold = 0.09090909090909091\n"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "kf = KFold(n_splits=k, random_state=10, shuffle=True)\n",
    "kf.get_n_splits(Xvals)\n",
    "\n",
    "y_test_veck = np.zeros(N_loo)\n",
    "y_pred_veck = np.zeros(N_loo)\n",
    "\n",
    "k_ind = int(0)\n",
    "\n",
    "for train_index, test_index in kf.split(Xvals):\n",
    "    X_traink, X_testk = Xvals[train_index], Xvals[test_index]\n",
    "    y_traink, y_testk = yvals[train_index], yvals[test_index]\n",
    "    LogReg = LogisticRegression(random_state=0, multi_class='multinomial',solver='newton-cg')\n",
    "    LogReg.fit(X_traink, y_traink)\n",
    "    y_predk = LogReg.predict(X_testk)\n",
    "    y_test_veck[test_index] = y_testk\n",
    "    y_pred_veck[test_index] = y_predk\n",
    "    \n",
    "    # print('MSE for test set', k_ind, ' is', MSE_vec_kf[k_ind])\n",
    "    k_ind += 1\n",
    "\n",
    "mse_test_k = np.sum(y_test_veck != y_pred_veck)/(y_pred_veck.shape[0])\n",
    "\n",
    "print('test estimate MSE k-fold =', mse_test_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[55,  4,  0],\n",
       "       [ 7, 62,  2],\n",
       "       [ 1,  2, 43]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrixk = confusion_matrix(y_test_veck, y_pred_veck)\n",
    "confusion_matrixk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.87      0.93      0.90        59\n",
      "         2.0       0.91      0.87      0.89        71\n",
      "         3.0       0.96      0.93      0.95        46\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       176\n",
      "   macro avg       0.91      0.91      0.91       176\n",
      "weighted avg       0.91      0.91      0.91       176\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_veck, y_pred_veck))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
